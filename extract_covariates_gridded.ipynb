{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19604ed-1dd6-4ad5-92a8-41b46f1abd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from skimage.filters.rank import majority\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import BallTree\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib widget\n",
    "\n",
    "from distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=5, threads_per_worker=2)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18961db2-4b0a-4934-a634-0616ce808254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define input data and covariates for extraction\n",
    "\"\"\"\n",
    "# set the year of analysis\n",
    "year = 2018\n",
    "\n",
    "# path to input directory\n",
    "inDIR = 'C:/Users/sean.kearney/OneDrive - USDA/Documents/Projects/GPS_v_hetgen/data/'\n",
    "# file name of gridded path intensity data (output from gps_to_gridded_path_intensity.ipynb)\n",
    "griddata_f = str(year) + '_grazing_time_gridded_all.csv'\n",
    "\n",
    "# create dictionary of paths to dynamic time-series co-variates\n",
    "ts_covariates = {\n",
    "    'Biomass': {\n",
    "        'path': 'C:/SPK_local/data/rasters/HLS/HLS_CARM_biomass/CPER_biomass_pred_simp_' + str(year) + '.tif'},\n",
    "    'CP': {\n",
    "        'path': 'C:/SPK_local/data/rasters/HLS/HLS_quality/CPER_CP_' + str(year) + '.tif'},\n",
    "    'DOM': {\n",
    "        'path': 'C:/SPK_local/data/rasters/HLS/HLS_quality/CPER_DOM_' + str(year) + '.tif'}\n",
    "}\n",
    "\n",
    "# create dictionary of paths to static co-variates\n",
    "static_covariates = {\n",
    "    'TPC': {\n",
    "        'path': 'C:/SPK_local/data/rasters/DEM/TopoClass25m.tif'},\n",
    "    'dFence': {\n",
    "        'path': 'C:/SPK_local/data/rasters/Masks/CPER_dist_to_fence_2017.tif'},\n",
    "    'dTank': {\n",
    "        'path': 'C:/SPK_local/data/rasters/Masks/CPER_dist_to_tank_2017.tif'}\n",
    "}\n",
    "\n",
    "# path to 1 m vegetation raster\n",
    "veg_f = 'G:/neon_v18/neon_class_2017_v18.tif'\n",
    "#veg_f = 'T:/3-GIS/CPER/Layers/NEON/veg_maps_v18/neon_class_2017_v18.tif'\n",
    "\n",
    "# path to shapefile containing pasture corners\n",
    "corners_f = 'C:/SPK_local/data/vectors/CPER_features/CPER_pasture_corners.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db320c58-7c76-4a78-a67f-3864cb12749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create dictionaries for remapping raster integer values to character strings\n",
    "\"\"\"\n",
    "# create dictionary to remap plant community values to strings\n",
    "veg_dict = {'C4': [0],\n",
    "            'Annual': [1],\n",
    "            'Bare_veg': [2, 3], # combines Bare_veg with FORB\n",
    "            'C3': [4, 5], # combines HECO and PASM\n",
    "            'C3_C4_mix': [6, 7],\n",
    "            'Saltgrass': [8],\n",
    "            'Shrub': [9],\n",
    "            'Bare': [10],\n",
    "            'UNK': [11, 255]\n",
    "            }\n",
    "\n",
    "# create dictionary to remap topgoraphic position class (TPC) values to strings\n",
    "TPC_dict = {\n",
    "    1.0: 'Lowlands', 2.0: 'Lowlands', 3.0: 'Lowlands',\n",
    "    4.0: 'Other',\n",
    "    5.0: 'Flat Plains',\n",
    "    6.0: 'Open Slopes', \n",
    "    7.0: 'Other', \n",
    "    8.0: 'Highlands', 9.0: 'Highlands', 10.0: 'Highlands'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a97269-72de-4bc1-a8eb-98e733a9693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biomass\n",
      "CP\n",
      "DOM\n",
      "TPC\n",
      "dFence\n",
      "dTank\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert gridded covariates to xarray datasets\n",
    "\"\"\"\n",
    "for i in ts_covariates:\n",
    "    print(i)\n",
    "    xr_tmp = xr.open_rasterio(ts_covariates[i]['path'])\n",
    "    xr_tmp = xr_tmp.rename({'band': 'date'})\n",
    "    xr_tmp['date'] = [datetime.datetime(2017, 1, 1) + \n",
    "                   datetime.timedelta(d-1) for d in xr_tmp['date'].astype('float').values]\n",
    "    ts_covariates[i]['data'] = xr_tmp\n",
    "\n",
    "for i in static_covariates:\n",
    "    print(i)\n",
    "    xr_tmp = xr.open_rasterio(static_covariates[i]['path']).squeeze('band')\n",
    "    if i == 'TPC':\n",
    "        xr_tmp = xr_tmp.astype('int')\n",
    "    static_covariates[i]['data'] = xr_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d868d4-df63-464e-84ae-0186926b8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running majority filters\n",
      "1 of 3\n",
      "2 of 3\n",
      "3 of 3\n",
      "Majority filters finished!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare plant community (veg) covariates to be added to static covariates\n",
    "\"\"\"\n",
    "# load 1 m vegetation raster to lazy xarray DataAarray\n",
    "xr_veg = xr.open_rasterio(veg_f).squeeze('band')#.chunk({'y': 300, 'x': 300})\n",
    "# rename the DataArray\n",
    "xr_veg.name = 'VEG_FG'\n",
    "\n",
    "# run majority filter multiple times to change NAN values to the majority nearest-neighbour value\n",
    "print('Running majority filters')\n",
    "print('1 of 3')\n",
    "img_maj1 = majority(xr_veg.values, np.ones((3, 3)))\n",
    "xr_veg1 = xr_veg.where(xr_veg != 255, other=img_maj1)\n",
    "print('2 of 3')\n",
    "img_maj2 = majority(xr_veg1.values, np.ones((3, 3)))\n",
    "xr_veg2 = xr_veg1.where(xr_veg1 != 255, other=img_maj2)\n",
    "print('3 of 3')\n",
    "img_maj3 = majority(xr_veg2.values, np.ones((3, 3)))\n",
    "xr_veg3 = xr_veg2.where(xr_veg2 != 255, other=img_maj3)\n",
    "print('Majority filters finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0375ac57-5840-468f-8a95-e7ec748416e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ad34db0187478faa4ad0d85c08c989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot the vegetation data after each filtering iteration to determine final filtering level\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(6, 6), sharex=True, sharey=True)\n",
    "cmap_veg = ListedColormap(['blue', 'orange', 'red', 'green', 'lightseagreen', 'pink', 'yellow', 'brown', 'black'])\n",
    "norm = BoundaryNorm([0, 1, 2, 4, 6, 8, 9, 10, 11], cmap_veg.N, clip=True)\n",
    "show(xr_veg, cmap=cmap_veg, norm=norm, ax=axs.flatten()[0])\n",
    "show(xr_veg1, cmap=cmap_veg, norm=norm, ax=axs.flatten()[1])\n",
    "show(xr_veg2, cmap=cmap_veg, norm=norm, ax=axs.flatten()[2])\n",
    "show(xr_veg3, cmap=cmap_veg, norm=norm, ax=axs.flatten()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fefd07a4-ea45-4d80-af70-01f4a271bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSave filtered vegetation maps as GeoTIFFs for preview in GIS if desired\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save filtered vegetation maps as GeoTIFFs for preview in GIS if desired\n",
    "\"\"\"\n",
    "# from rasterio.crs import CRS\n",
    "# import rasterio as rio\n",
    "# out_profile = {'driver': 'GTiff',\n",
    "#                        'dtype': 'int16',\n",
    "#                        'nodata': -999,\n",
    "#                        'width': len(xr_veg.x),\n",
    "#                        'height': len(xr_veg.y),\n",
    "#                        'count': 1,\n",
    "#                        'crs': CRS.from_dict(init='epsg:32613'),\n",
    "#                        'transform': rio.Affine(1.0, 0.0, np.min(xr_veg.x - 0.5).data,\n",
    "#                                                0.0, -1.0, np.max(xr_veg.y + 0.5).data),\n",
    "#                        'tiled': False}\n",
    "# with rio.open('G:/neon_v18/neon_class_2017_v18_maj1.tif',\n",
    "#               'w', **out_profile) as dst:\n",
    "#     dst.write(xr_veg1.data[np.newaxis, :, :])\n",
    "# with rio.open('G:/neon_v18/neon_class_2017_v18_maj2.tif',\n",
    "#           'w', **out_profile) as dst:\n",
    "#     dst.write(xr_veg2.data[np.newaxis, :, :])\n",
    "# with rio.open('G:/neon_v18/neon_class_2017_v18_maj3.tif',\n",
    "#           'w', **out_profile) as dst:\n",
    "#     dst.write(xr_veg3.data[np.newaxis, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703335b4-3cc0-405a-91c0-c4c3e3b2744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4\n",
      "Annual\n",
      "Bare_veg\n",
      "C3\n",
      "C3_C4_mix\n",
      "Saltgrass\n",
      "Shrub\n",
      "Bare\n",
      "UNK\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the plant community metrics to be extracted\n",
    "\"\"\"\n",
    "\n",
    "# specify the final filtered vegetation map to use as a covariate\n",
    "xr_veg = xr_veg3\n",
    "\n",
    "# create a 30 m coarsened DataArray of counts 1 m cells in each 30 m cell\n",
    "xr_veg_30m = xr_veg.coarsen(dim=dict(x=30, y=30), boundary='trim').count()\n",
    "# convert DataArray to Dataset\n",
    "xr_veg_30m = xr_veg_30m.to_dataset()\n",
    "\n",
    "# loop through each plant community class, convert counts to a proportion, rename the class and add it as a variable\n",
    "for k in veg_dict:\n",
    "    print(k)\n",
    "    # get count of 1 m cells for the individual class in the 30 m cell\n",
    "    xr_veg_30m = xr_veg_30m.assign(TMP=(['y', 'x'],\n",
    "                                  xr_veg.where(xr_veg.isin(veg_dict[k])).coarsen(dim=dict(x=30, y=30),\n",
    "                                                                           boundary='trim').count()))\n",
    "    # convert the count to a proportion based on the total number of 1 m cells\n",
    "    xr_veg_30m['TMP'] = xr_veg_30m['TMP'] / xr_veg_30m['VEG_FG']\n",
    "    # rename the class based on the dictionary\n",
    "    xr_veg_30m = xr_veg_30m.rename({'TMP': k})\n",
    "\n",
    "# 'snap' the 30 m plant community data to the coordinates of the other 30 m gridded datasets\n",
    "xr_veg_30m = xr_veg_30m.sel(y=static_covariates['dFence']['data']['y'],\n",
    "                        x=static_covariates['dFence']['data']['x'],\n",
    "                        method='nearest').reindex_like(static_covariates['dFence']['data'], \n",
    "                                                       method='nearest')\n",
    "# replace any NAN values with zeros\n",
    "xr_veg_30m = xr_veg_30m.fillna(0)\n",
    "\n",
    "# identify the dominant plant community class in each 30 m cell as the class with the greatest proportion\n",
    "static_covariates['PC_dmt'] = {'data':\n",
    "                               xr_veg_30m[[i for i in veg_dict]].to_array().idxmax('variable')}\n",
    "# calculate the proprotional coverage of the dominant class\n",
    "static_covariates['PC_pct'] = {'data':\n",
    "                               xr_veg_30m[[i for i in veg_dict]].to_array().max('variable')}\n",
    "# calculate the Shannon diversity index of all classes in the 30 m grid cell\n",
    "static_covariates['PC_div'] = {'data':\n",
    "                              (xr_veg_30m[[i for i in veg_dict]].to_array() * \n",
    "                               xr.ufuncs.log(xr_veg_30m[[i for i in veg_dict]].to_array().where(\n",
    "                                   xr_veg_30m[[i for i in veg_dict]].to_array() != 0))).sum('variable') * -1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe2f299-acc8-4a02-a544-e46a008144ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef9cfc73d9b4880bd29ef9ccfdcc5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sanity check of vegetation metrics by plotting\n",
    "\"\"\"\n",
    "# create an integer version of the dominant vegetation classes for plotting\n",
    "xr_PC_dmt_int = static_covariates['PC_dmt']['data'].copy()\n",
    "xr_PC_dmt_int.values = np.array([veg_dict[i][0] for i in static_covariates['PC_dmt']['data'].values.flatten()]).reshape(xr_PC_dmt_int.shape)\n",
    "\n",
    "# plot the three vegetation metrics together for comparison\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\n",
    "show(xr_PC_dmt_int, cmap='tab10', ax=axs[0])\n",
    "show(static_covariates['PC_pct']['data'], cmap='viridis', ax=axs[1])\n",
    "show(static_covariates['PC_div']['data'], cmap='magma', ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3958ea03-73d3-4780-9f4a-f7985aba3d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a12bab1c52438b8bd990310901aa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loop through static and time series co-variates and extract for each grid cell\n",
    "\"\"\"\n",
    "# read in the gridded path intensity dataset\n",
    "df_wkly_grid = pd.read_csv(os.path.join(inDIR, griddata_f), engine='python')\n",
    "\n",
    "for g in tqdm(df_wkly_grid.groupby('week')):\n",
    "    target_lon = xr.DataArray(g[1]['UTM_X'], dims=\"points\")\n",
    "    target_lat = xr.DataArray(g[1]['UTM_Y'], dims=\"points\")\n",
    "    # loop through static covariates and get values\n",
    "    for var in static_covariates:\n",
    "        xr_tmp = static_covariates[var]['data']\n",
    "        df_wkly_grid.loc[df_wkly_grid['week'] == g[0], var] = xr_tmp.sel(\n",
    "            x=target_lon, y=target_lat, method='nearest').values\n",
    "    # loop through time series covariates and get weekly average\n",
    "    for var in ts_covariates:\n",
    "        xr_tmp = ts_covariates[var]['data']\n",
    "        df_wkly_grid.loc[df_wkly_grid['week'] == g[0], var] = xr_tmp[xr_tmp.date.dt.isocalendar().week == g[0]].mean('date').sel(\n",
    "            x=target_lon, y=target_lat, method='nearest').values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d0975a-6330-41cc-8907-cf06224518c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16356e8a8b7e43f5979c85691f64c1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get distance to nearest pasture corner for each pasture\n",
    "\"\"\"\n",
    "# read in shapefile of corners\n",
    "gdf_corners = gpd.read_file(corners_f)\n",
    "\n",
    "# loop through pastures and get the distance from each fix to the pasture corner\n",
    "for past_i in tqdm(df_wkly_grid['Pasture'].unique()):\n",
    "    #print(past_i)\n",
    "    gdf_corners_p = gdf_corners[gdf_corners['Pasture'] == past_i]\n",
    "    x_coords = [i[0][0] for i in gdf_corners_p.apply(lambda x: x.geometry.coords.xy, axis=1)]\n",
    "    y_coords = [i[1][0] for i in gdf_corners_p.apply(lambda x: x.geometry.coords.xy, axis=1)]\n",
    "\n",
    "    # Create a BallTree object\n",
    "    # borrowed from: https://stackoverflow.com/questions/58893719/find-nearest-point-in-other-dataframe-with-a-lot-of-data\n",
    "    tree = BallTree(np.array(list(zip(x_coords, y_coords))), leaf_size=2)\n",
    "\n",
    "    #Query the BallTree on all GPS coordinates from collars deployed in the pasture to find the distance\n",
    "    # to the nearest pixel within the pasture and its id\n",
    "    dist_tmp, id_tmp= tree.query(\n",
    "        df_wkly_grid.loc[df_wkly_grid['Pasture'] == past_i, ['UTM_X', 'UTM_Y']].values, # The input array for the query\n",
    "        k=1, # The number of nearest neighbors\n",
    "    )\n",
    "    df_wkly_grid.loc[df_wkly_grid['Pasture'] == past_i, 'dCorner'] = dist_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1873f9d8-d30d-418a-9cb5-8435e13bff69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index_id          int64\n",
       "mod_data         object\n",
       "week              int64\n",
       "Pasture          object\n",
       "Steer_ID         object\n",
       "UTM_X           float64\n",
       "UTM_Y           float64\n",
       "grazing_secs    float64\n",
       "TPC             float64\n",
       "dFence          float64\n",
       "dTank           float64\n",
       "PC_dmt           object\n",
       "PC_pct          float64\n",
       "PC_div          float64\n",
       "Biomass         float32\n",
       "CP              float32\n",
       "DOM             float32\n",
       "dCorner         float64\n",
       "TPC_c            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Make sure all variables are in the correct datatype format\n",
    "\"\"\"\n",
    "# convert topographic position class (TPC) values to strings\n",
    "df_wkly_grid['TPC_c'] = [TPC_dict[c] for c in df_wkly_grid['TPC']]\n",
    "\n",
    "# print the datatypes for each field\n",
    "display(df_wkly_grid.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893f6735-258e-4b25-b8af-ba045093204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write gridded data with extrations to disk\n",
    "\"\"\"\n",
    "df_wkly_grid.to_csv(os.path.join(inDIR, re.sub('.csv', '_extracted.csv', griddata_f)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
